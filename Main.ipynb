{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import gym\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentConfig:\n",
    "    # Learning\n",
    "    gamma = 0.99\n",
    "    plot_every = 5\n",
    "    update_freq = 1\n",
    "    k_epoch = 3\n",
    "    learning_rate = 0.02\n",
    "    lmbda = 0.95\n",
    "    eps_clip = 0.2\n",
    "    v_coef = 1\n",
    "    entropy_coef = 0.01\n",
    "    \n",
    "    # Memory\n",
    "    memory_size = 400\n",
    "\n",
    "    train_cartpole = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MlpPolicy(nn.Module):\n",
    "    def __init__(self, action_size, input_size=4):\n",
    "        super(MlpPolicy, self).__init__()\n",
    "        self.action_size = action_size\n",
    "        self.input_size = input_size\n",
    "        self.fc1 = nn.Linear(self.input_size, 24)\n",
    "        self.fc2 = nn.Linear(24, 24)\n",
    "        self.fc3_pi = nn.Linear(24, self.action_size)\n",
    "        self.fc3_v = nn.Linear(24, 1)\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.relu = nn.ReLU()\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "    def pi(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.fc3_pi(x)\n",
    "        return self.softmax(x)\n",
    "\n",
    "    def v(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.fc3_v(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_graph(reward_history, avg_reward):\n",
    "    df = pd.DataFrame({'x': range(len(reward_history)), 'Reward': reward_history, 'Average': avg_reward})\n",
    "    plt.style.use('seaborn-darkgrid')\n",
    "    palette = plt.get_cmap('Set1')\n",
    "\n",
    "    plt.plot(df['x'], df['Reward'], marker='', color=palette(1), linewidth=0.8, alpha=0.9, label='Reward')\n",
    "    # plt.plot(df['x'], df['Average'], marker='', color='tomato', linewidth=1, alpha=0.9, label='Average')\n",
    "\n",
    "    # plt.legend(loc='upper left')\n",
    "    plt.title(\"CartPole\", fontsize=14)\n",
    "    plt.xlabel(\"episode\", fontsize=12)\n",
    "    plt.ylabel(\"score\", fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent(AgentConfig):\n",
    "    def __init__(self):\n",
    "        self.env = gym.make('CartPole-v0')\n",
    "        self.action_size = self.env.action_space.n  # 2 for cartpole\n",
    "        if self.train_cartpole:\n",
    "            self.policy_network = MlpPolicy(action_size=self.action_size).to(device)\n",
    "        self.optimizer = optim.Adam(self.policy_network.parameters(), lr=self.learning_rate)\n",
    "        self.scheduler = optim.lr_scheduler.StepLR(self.optimizer, step_size=self.k_epoch,\n",
    "                                                   gamma=0.999)\n",
    "        self.loss = 0\n",
    "        self.criterion = nn.MSELoss()\n",
    "        self.memory = {\n",
    "            'state': [], 'action': [], 'reward': [], 'next_state': [], 'action_prob': [], 'terminal': [], 'count': 0,\n",
    "            'advantage': [], 'td_target': torch.FloatTensor([])\n",
    "        }\n",
    "\n",
    "    def new_random_game(self):\n",
    "        self.env.reset()\n",
    "        action = self.env.action_space.sample()\n",
    "        screen, reward, terminal, info = self.env.step(action)\n",
    "        return screen, reward, action, terminal\n",
    "\n",
    "    def train(self):\n",
    "        episode = 0\n",
    "        step = 0\n",
    "        reward_history = []\n",
    "        avg_reward = []\n",
    "        solved = False\n",
    "\n",
    "        # A new episode\n",
    "        while not solved:\n",
    "            start_step = step\n",
    "            episode += 1\n",
    "            episode_length = 0\n",
    "\n",
    "            # Get initial state\n",
    "            state, reward, action, terminal = self.new_random_game()\n",
    "            current_state = state\n",
    "            total_episode_reward = 1\n",
    "\n",
    "            # A step in an episode\n",
    "            while not solved:\n",
    "                step += 1\n",
    "                episode_length += 1\n",
    "\n",
    "                # Choose action\n",
    "                prob_a = self.policy_network.pi(torch.FloatTensor(current_state).to(device))\n",
    "                # print(prob_a)\n",
    "                action = torch.distributions.Categorical(prob_a).sample().item()\n",
    "\n",
    "                # Act\n",
    "                state, reward, terminal, _ = self.env.step(action)\n",
    "                new_state = state\n",
    "\n",
    "                reward = -1 if terminal else reward\n",
    "\n",
    "                self.add_memory(current_state, action, reward/10.0, new_state, terminal, prob_a[action].item())\n",
    "\n",
    "                current_state = new_state\n",
    "                total_episode_reward += reward\n",
    "\n",
    "                if terminal:\n",
    "                    episode_length = step - start_step\n",
    "                    reward_history.append(total_episode_reward)\n",
    "                    avg_reward.append(sum(reward_history[-10:])/10.0)\n",
    "\n",
    "                    self.finish_path(episode_length)\n",
    "\n",
    "                    if len(reward_history) > 100 and sum(reward_history[-100:-1]) / 100 >= 195:\n",
    "                        solved = True\n",
    "\n",
    "                    print('episode: %.2f, total step: %.2f, last_episode length: %.2f, last_episode_reward: %.2f, '\n",
    "                          'loss: %.4f, lr: %.4f' % (episode, step, episode_length, total_episode_reward, self.loss,\n",
    "                                                    self.scheduler.get_lr()[0]))\n",
    "\n",
    "                    self.env.reset()\n",
    "\n",
    "                    break\n",
    "\n",
    "            if episode % self.update_freq == 0:\n",
    "                for _ in range(self.k_epoch):\n",
    "                    self.update_network()\n",
    "\n",
    "            if episode % self.plot_every == 0:\n",
    "                plot_graph(reward_history, avg_reward)\n",
    "\n",
    "        self.env.close()\n",
    "\n",
    "    def update_network(self):\n",
    "        # get ratio\n",
    "        pi = self.policy_network.pi(torch.FloatTensor(self.memory['state']).to(device))\n",
    "        new_probs_a = torch.gather(pi, 1, torch.tensor(self.memory['action']))\n",
    "        old_probs_a = torch.FloatTensor(self.memory['action_prob'])\n",
    "        ratio = torch.exp(torch.log(new_probs_a) - torch.log(old_probs_a))\n",
    "\n",
    "        # surrogate loss\n",
    "        surr1 = ratio * torch.FloatTensor(self.memory['advantage'])\n",
    "        surr2 = torch.clamp(ratio, 1 - self.eps_clip, 1 + self.eps_clip) * torch.FloatTensor(self.memory['advantage'])\n",
    "        pred_v = self.policy_network.v(torch.FloatTensor(self.memory['state']).to(device))\n",
    "        v_loss = 0.5 * (pred_v - self.memory['td_target']).pow(2)  # Huber loss\n",
    "        entropy = torch.distributions.Categorical(pi).entropy()\n",
    "        entropy = torch.tensor([[e] for e in entropy])\n",
    "        self.loss = (-torch.min(surr1, surr2) + self.v_coef * v_loss - self.entropy_coef * entropy).mean()\n",
    "\n",
    "        self.optimizer.zero_grad()\n",
    "        self.loss.backward()\n",
    "        self.optimizer.step()\n",
    "        self.scheduler.step()\n",
    "\n",
    "    def add_memory(self, s, a, r, next_s, t, prob):\n",
    "        if self.memory['count'] < self.memory_size:\n",
    "            self.memory['count'] += 1\n",
    "        else:\n",
    "            self.memory['state'] = self.memory['state'][1:]\n",
    "            self.memory['action'] = self.memory['action'][1:]\n",
    "            self.memory['reward'] = self.memory['reward'][1:]\n",
    "            self.memory['next_state'] = self.memory['next_state'][1:]\n",
    "            self.memory['terminal'] = self.memory['terminal'][1:]\n",
    "            self.memory['action_prob'] = self.memory['action_prob'][1:]\n",
    "            self.memory['advantage'] = self.memory['advantage'][1:]\n",
    "            self.memory['td_target'] = self.memory['td_target'][1:]\n",
    "\n",
    "        self.memory['state'].append(s)\n",
    "        self.memory['action'].append([a])\n",
    "        self.memory['reward'].append([r])\n",
    "        self.memory['next_state'].append(next_s)\n",
    "        self.memory['terminal'].append([1 - t])\n",
    "        self.memory['action_prob'].append(prob)\n",
    "\n",
    "    def finish_path(self, length):\n",
    "        state = self.memory['state'][-length:]\n",
    "        reward = self.memory['reward'][-length:]\n",
    "        next_state = self.memory['next_state'][-length:]\n",
    "        terminal = self.memory['terminal'][-length:]\n",
    "\n",
    "        td_target = torch.FloatTensor(reward) + \\\n",
    "                    self.gamma * self.policy_network.v(torch.FloatTensor(next_state)) * torch.FloatTensor(terminal)\n",
    "        delta = td_target - self.policy_network.v(torch.FloatTensor(state))\n",
    "        delta = delta.detach().numpy()\n",
    "\n",
    "        # get advantage\n",
    "        advantages = []\n",
    "        adv = 0.0\n",
    "        for d in delta[::-1]:\n",
    "            adv = self.gamma * self.lmbda * adv + d[0]\n",
    "            advantages.append([adv])\n",
    "        advantages.reverse()\n",
    "\n",
    "        if self.memory['td_target'].shape == torch.Size([1, 0]):\n",
    "            self.memory['td_target'] = td_target.data\n",
    "        else:\n",
    "            self.memory['td_target'] = torch.cat((self.memory['td_target'], td_target.data), dim=0)\n",
    "        self.memory['advantage'] += advantages\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 1.00, total step: 56.00, last_episode length: 56.00, last_episode_reward: 55.00, loss: 0.0000, lr: 0.0200\n",
      "episode: 2.00, total step: 103.00, last_episode length: 47.00, last_episode_reward: 46.00, loss: -1.1789, lr: 0.0200\n",
      "episode: 3.00, total step: 143.00, last_episode length: 40.00, last_episode_reward: 39.00, loss: -1.1360, lr: 0.0199\n",
      "episode: 4.00, total step: 181.00, last_episode length: 38.00, last_episode_reward: 37.00, loss: -1.0958, lr: 0.0199\n",
      "episode: 5.00, total step: 224.00, last_episode length: 43.00, last_episode_reward: 42.00, loss: -1.0472, lr: 0.0199\n",
      "episode: 6.00, total step: 237.00, last_episode length: 13.00, last_episode_reward: 12.00, loss: -1.0295, lr: 0.0199\n",
      "episode: 7.00, total step: 266.00, last_episode length: 29.00, last_episode_reward: 28.00, loss: -0.9874, lr: 0.0199\n",
      "episode: 8.00, total step: 277.00, last_episode length: 11.00, last_episode_reward: 10.00, loss: -0.9572, lr: 0.0198\n",
      "episode: 9.00, total step: 295.00, last_episode length: 18.00, last_episode_reward: 17.00, loss: -0.9242, lr: 0.0198\n",
      "episode: 10.00, total step: 350.00, last_episode length: 55.00, last_episode_reward: 54.00, loss: -0.8927, lr: 0.0198"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MR.Mohebbian\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n",
      "C:\\Users\\MR.Mohebbian\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "episode: 11.00, total step: 394.00, last_episode length: 44.00, last_episode_reward: 43.00, loss: -0.9218, lr: 0.0198\n",
      "episode: 12.00, total step: 433.00, last_episode length: 39.00, last_episode_reward: 38.00, loss: -0.9225, lr: 0.0198\n",
      "episode: 13.00, total step: 477.00, last_episode length: 44.00, last_episode_reward: 43.00, loss: -0.8633, lr: 0.0197\n",
      "episode: 14.00, total step: 530.00, last_episode length: 53.00, last_episode_reward: 52.00, loss: -0.8496, lr: 0.0197\n",
      "episode: 15.00, total step: 554.00, last_episode length: 24.00, last_episode_reward: 23.00, loss: -0.8391, lr: 0.0197\n",
      "episode: 16.00, total step: 579.00, last_episode length: 25.00, last_episode_reward: 24.00, loss: -0.8218, lr: 0.0197\n",
      "episode: 17.00, total step: 632.00, last_episode length: 53.00, last_episode_reward: 52.00, loss: -0.8126, lr: 0.0197\n",
      "episode: 18.00, total step: 678.00, last_episode length: 46.00, last_episode_reward: 45.00, loss: -0.8331, lr: 0.0196\n",
      "episode: 19.00, total step: 708.00, last_episode length: 30.00, last_episode_reward: 29.00, loss: -0.8823, lr: 0.0196\n",
      "episode: 20.00, total step: 799.00, last_episode length: 91.00, last_episode_reward: 90.00, loss: -0.8621, lr: 0.0196"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MR.Mohebbian\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "episode: 21.00, total step: 870.00, last_episode length: 71.00, last_episode_reward: 70.00, loss: -0.9256, lr: 0.0196\n",
      "episode: 22.00, total step: 945.00, last_episode length: 75.00, last_episode_reward: 74.00, loss: -0.9497, lr: 0.0196\n",
      "episode: 23.00, total step: 1023.00, last_episode length: 78.00, last_episode_reward: 77.00, loss: -0.9925, lr: 0.0195\n",
      "episode: 24.00, total step: 1075.00, last_episode length: 52.00, last_episode_reward: 51.00, loss: -1.0464, lr: 0.0195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MR.Mohebbian\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n",
      "C:\\Users\\MR.Mohebbian\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 25.00, total step: 1140.00, last_episode length: 65.00, last_episode_reward: 64.00, loss: -1.0492, lr: 0.0195\n",
      "episode: 26.00, total step: 1182.00, last_episode length: 42.00, last_episode_reward: 41.00, loss: -1.0420, lr: 0.0195\n",
      "episode: 27.00, total step: 1296.00, last_episode length: 114.00, last_episode_reward: 113.00, loss: -0.9854, lr: 0.0195\n",
      "episode: 28.00, total step: 1349.00, last_episode length: 53.00, last_episode_reward: 52.00, loss: -1.0228, lr: 0.0194\n",
      "episode: 29.00, total step: 1447.00, last_episode length: 98.00, last_episode_reward: 97.00, loss: -1.0089, lr: 0.0194\n",
      "episode: 30.00, total step: 1510.00, last_episode length: 63.00, last_episode_reward: 62.00, loss: -1.0016, lr: 0.0194\n",
      "episode: 31.00, total step: 1586.00, last_episode length: 76.00, last_episode_reward: 75.00, loss: -0.9827, lr: 0.0194\n",
      "episode: 32.00, total step: 1722.00, last_episode length: 136.00, last_episode_reward: 135.00, loss: -1.0345, lr: 0.0194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MR.Mohebbian\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 33.00, total step: 1893.00, last_episode length: 171.00, last_episode_reward: 170.00, loss: -1.0352, lr: 0.0194\n",
      "episode: 34.00, total step: 1949.00, last_episode length: 56.00, last_episode_reward: 55.00, loss: -1.1472, lr: 0.0193\n",
      "episode: 35.00, total step: 2047.00, last_episode length: 98.00, last_episode_reward: 97.00, loss: -1.1027, lr: 0.0193\n",
      "episode: 36.00, total step: 2136.00, last_episode length: 89.00, last_episode_reward: 88.00, loss: -1.0888, lr: 0.0193\n",
      "episode: 37.00, total step: 2237.00, last_episode length: 101.00, last_episode_reward: 100.00, loss: -1.0880, lr: 0.0193"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MR.Mohebbian\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "episode: 38.00, total step: 2311.00, last_episode length: 74.00, last_episode_reward: 73.00, loss: -0.9774, lr: 0.0193\n",
      "episode: 39.00, total step: 2424.00, last_episode length: 113.00, last_episode_reward: 112.00, loss: -0.9556, lr: 0.0192\n",
      "episode: 40.00, total step: 2538.00, last_episode length: 114.00, last_episode_reward: 113.00, loss: -0.9579, lr: 0.0192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MR.Mohebbian\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 41.00, total step: 2666.00, last_episode length: 128.00, last_episode_reward: 127.00, loss: -1.0184, lr: 0.0192\n",
      "episode: 42.00, total step: 2758.00, last_episode length: 92.00, last_episode_reward: 91.00, loss: -1.0296, lr: 0.0192\n",
      "episode: 43.00, total step: 2844.00, last_episode length: 86.00, last_episode_reward: 85.00, loss: -1.0312, lr: 0.0192\n",
      "episode: 44.00, total step: 2938.00, last_episode length: 94.00, last_episode_reward: 93.00, loss: -1.0271, lr: 0.0191\n",
      "episode: 45.00, total step: 3014.00, last_episode length: 76.00, last_episode_reward: 75.00, loss: -1.0030, lr: 0.0191\n",
      "episode: 46.00, total step: 3128.00, last_episode length: 114.00, last_episode_reward: 113.00, loss: -0.9094, lr: 0.0191\n",
      "episode: 47.00, total step: 3213.00, last_episode length: 85.00, last_episode_reward: 84.00, loss: -0.9475, lr: 0.0191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MR.Mohebbian\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 48.00, total step: 3412.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.9277, lr: 0.0191\n",
      "episode: 49.00, total step: 3611.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -1.0692, lr: 0.0190\n",
      "episode: 50.00, total step: 3778.00, last_episode length: 167.00, last_episode_reward: 166.00, loss: -1.1641, lr: 0.0190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MR.Mohebbian\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 51.00, total step: 3977.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -1.0910, lr: 0.0190\n",
      "episode: 52.00, total step: 4176.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -1.0458, lr: 0.0190\n",
      "episode: 53.00, total step: 4291.00, last_episode length: 115.00, last_episode_reward: 114.00, loss: -1.0938, lr: 0.0190\n",
      "episode: 54.00, total step: 4386.00, last_episode length: 95.00, last_episode_reward: 94.00, loss: -1.0386, lr: 0.0189\n",
      "episode: 55.00, total step: 4585.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -1.0934, lr: 0.0189\n",
      "episode: 56.00, total step: 4784.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -1.1100, lr: 0.0189\n",
      "episode: 57.00, total step: 4983.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -1.1048, lr: 0.0189"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MR.Mohebbian\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "episode: 58.00, total step: 5182.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -1.0922, lr: 0.0189\n",
      "episode: 59.00, total step: 5381.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -1.0934, lr: 0.0189\n",
      "episode: 60.00, total step: 5580.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -1.0861, lr: 0.0188\n",
      "episode: 61.00, total step: 5779.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -1.0724, lr: 0.0188\n",
      "episode: 62.00, total step: 5978.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -1.0298, lr: 0.0188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MR.Mohebbian\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 63.00, total step: 6177.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -1.0158, lr: 0.0188\n",
      "episode: 64.00, total step: 6376.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -1.0238, lr: 0.0188\n",
      "episode: 65.00, total step: 6575.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -1.0250, lr: 0.0187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MR.Mohebbian\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 66.00, total step: 6685.00, last_episode length: 110.00, last_episode_reward: 109.00, loss: -1.0356, lr: 0.0187\n",
      "episode: 67.00, total step: 6884.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -1.0042, lr: 0.0187\n",
      "episode: 68.00, total step: 7083.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -1.0113, lr: 0.0187\n",
      "episode: 69.00, total step: 7282.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -1.0938, lr: 0.0187\n",
      "episode: 70.00, total step: 7481.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -1.0430, lr: 0.0186\n",
      "episode: 71.00, total step: 7644.00, last_episode length: 163.00, last_episode_reward: 162.00, loss: -0.9835, lr: 0.0186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MR.Mohebbian\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 72.00, total step: 7843.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.9160, lr: 0.0186\n",
      "episode: 73.00, total step: 8042.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.9087, lr: 0.0186\n",
      "episode: 74.00, total step: 8241.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.9905, lr: 0.0186\n",
      "episode: 75.00, total step: 8399.00, last_episode length: 158.00, last_episode_reward: 157.00, loss: -0.9845, lr: 0.0186\n",
      "episode: 76.00, total step: 8598.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.9727, lr: 0.0185\n",
      "episode: 77.00, total step: 8797.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.9327, lr: 0.0185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MR.Mohebbian\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 78.00, total step: 8996.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.9416, lr: 0.0185\n",
      "episode: 79.00, total step: 9195.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.9606, lr: 0.0185\n",
      "episode: 80.00, total step: 9394.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.9455, lr: 0.0185\n",
      "episode: 81.00, total step: 9593.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.9389, lr: 0.0184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MR.Mohebbian\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 82.00, total step: 9792.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.9542, lr: 0.0184\n",
      "episode: 83.00, total step: 9931.00, last_episode length: 139.00, last_episode_reward: 138.00, loss: -0.9148, lr: 0.0184\n",
      "episode: 84.00, total step: 10069.00, last_episode length: 138.00, last_episode_reward: 137.00, loss: -0.8464, lr: 0.0184\n",
      "episode: 85.00, total step: 10268.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.9403, lr: 0.0184\n",
      "episode: 86.00, total step: 10439.00, last_episode length: 171.00, last_episode_reward: 170.00, loss: -0.9495, lr: 0.0184\n",
      "episode: 87.00, total step: 10638.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.9032, lr: 0.0183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MR.Mohebbian\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 88.00, total step: 10837.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.8183, lr: 0.0183\n",
      "episode: 89.00, total step: 11008.00, last_episode length: 171.00, last_episode_reward: 170.00, loss: -0.8971, lr: 0.0183\n",
      "episode: 90.00, total step: 11207.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.8269, lr: 0.0183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MR.Mohebbian\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 91.00, total step: 11406.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.7733, lr: 0.0183\n",
      "episode: 92.00, total step: 11602.00, last_episode length: 196.00, last_episode_reward: 195.00, loss: -0.8249, lr: 0.0182\n",
      "episode: 93.00, total step: 11801.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.9044, lr: 0.0182\n",
      "episode: 94.00, total step: 12000.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.9279, lr: 0.0182\n",
      "episode: 95.00, total step: 12199.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.8686, lr: 0.0182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MR.Mohebbian\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 96.00, total step: 12398.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.8406, lr: 0.0182\n",
      "episode: 97.00, total step: 12532.00, last_episode length: 134.00, last_episode_reward: 133.00, loss: -0.8238, lr: 0.0182\n",
      "episode: 98.00, total step: 12731.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.7529, lr: 0.0181\n",
      "episode: 99.00, total step: 12885.00, last_episode length: 154.00, last_episode_reward: 153.00, loss: -0.7111, lr: 0.0181\n",
      "episode: 100.00, total step: 13084.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.7829, lr: 0.0181\n",
      "episode: 101.00, total step: 13237.00, last_episode length: 153.00, last_episode_reward: 152.00, loss: -0.7378, lr: 0.0181\n",
      "episode: 102.00, total step: 13436.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.7796, lr: 0.0181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MR.Mohebbian\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 103.00, total step: 13635.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.7288, lr: 0.0180\n",
      "episode: 104.00, total step: 13815.00, last_episode length: 180.00, last_episode_reward: 179.00, loss: -0.8455, lr: 0.0180\n",
      "episode: 105.00, total step: 13994.00, last_episode length: 179.00, last_episode_reward: 178.00, loss: -0.7926, lr: 0.0180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MR.Mohebbian\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 106.00, total step: 14193.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.8042, lr: 0.0180\n",
      "episode: 107.00, total step: 14360.00, last_episode length: 167.00, last_episode_reward: 166.00, loss: -0.7165, lr: 0.0180\n",
      "episode: 108.00, total step: 14559.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.7133, lr: 0.0180\n",
      "episode: 109.00, total step: 14758.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.6760, lr: 0.0179\n",
      "episode: 110.00, total step: 14957.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.7450, lr: 0.0179\n",
      "episode: 111.00, total step: 15156.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.7117, lr: 0.0179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MR.Mohebbian\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 112.00, total step: 15355.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.7061, lr: 0.0179\n",
      "episode: 113.00, total step: 15498.00, last_episode length: 143.00, last_episode_reward: 142.00, loss: -0.7659, lr: 0.0179\n",
      "episode: 114.00, total step: 15697.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.6939, lr: 0.0178\n",
      "episode: 115.00, total step: 15855.00, last_episode length: 158.00, last_episode_reward: 157.00, loss: -0.7132, lr: 0.0178\n",
      "episode: 116.00, total step: 16021.00, last_episode length: 166.00, last_episode_reward: 165.00, loss: -0.7259, lr: 0.0178\n",
      "episode: 117.00, total step: 16220.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.7074, lr: 0.0178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MR.Mohebbian\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 118.00, total step: 16419.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.7420, lr: 0.0178\n",
      "episode: 119.00, total step: 16557.00, last_episode length: 138.00, last_episode_reward: 137.00, loss: -0.6613, lr: 0.0178\n",
      "episode: 120.00, total step: 16756.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.5940, lr: 0.0177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MR.Mohebbian\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 121.00, total step: 16955.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.5961, lr: 0.0177\n",
      "episode: 122.00, total step: 17154.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.7507, lr: 0.0177\n",
      "episode: 123.00, total step: 17353.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.6806, lr: 0.0177\n",
      "episode: 124.00, total step: 17552.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.6029, lr: 0.0177\n",
      "episode: 125.00, total step: 17751.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.6221, lr: 0.0176\n",
      "episode: 126.00, total step: 17950.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.6106, lr: 0.0176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MR.Mohebbian\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 127.00, total step: 18116.00, last_episode length: 166.00, last_episode_reward: 165.00, loss: -0.6031, lr: 0.0176\n",
      "episode: 128.00, total step: 18315.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.5533, lr: 0.0176\n",
      "episode: 129.00, total step: 18514.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.5317, lr: 0.0176\n",
      "episode: 130.00, total step: 18713.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.6028, lr: 0.0176\n",
      "episode: 131.00, total step: 18850.00, last_episode length: 137.00, last_episode_reward: 136.00, loss: -0.5705, lr: 0.0175\n",
      "episode: 132.00, total step: 19049.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.4921, lr: 0.0175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MR.Mohebbian\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 133.00, total step: 19248.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.4455, lr: 0.0175\n",
      "episode: 134.00, total step: 19447.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.5270, lr: 0.0175\n",
      "episode: 135.00, total step: 19646.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.5335, lr: 0.0175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MR.Mohebbian\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 136.00, total step: 19844.00, last_episode length: 198.00, last_episode_reward: 197.00, loss: -0.6202, lr: 0.0175\n",
      "episode: 137.00, total step: 20043.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.7529, lr: 0.0174\n",
      "episode: 138.00, total step: 20242.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.6997, lr: 0.0174\n",
      "episode: 139.00, total step: 20441.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.5473, lr: 0.0174\n",
      "episode: 140.00, total step: 20640.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.4887, lr: 0.0174\n",
      "episode: 141.00, total step: 20839.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.4933, lr: 0.0174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MR.Mohebbian\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 142.00, total step: 21038.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.5411, lr: 0.0174\n",
      "episode: 143.00, total step: 21180.00, last_episode length: 142.00, last_episode_reward: 141.00, loss: -0.5391, lr: 0.0173\n",
      "episode: 144.00, total step: 21339.00, last_episode length: 159.00, last_episode_reward: 158.00, loss: -0.4927, lr: 0.0173\n",
      "episode: 145.00, total step: 21538.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.5816, lr: 0.0173\n",
      "episode: 146.00, total step: 21737.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.7449, lr: 0.0173\n",
      "episode: 147.00, total step: 21936.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.8010, lr: 0.0173"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MR.Mohebbian\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "episode: 148.00, total step: 22135.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.6676, lr: 0.0172\n",
      "episode: 149.00, total step: 22334.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.6063, lr: 0.0172\n",
      "episode: 150.00, total step: 22533.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.2440, lr: 0.0172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MR.Mohebbian\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 151.00, total step: 22732.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.1715, lr: 0.0172\n",
      "episode: 152.00, total step: 22931.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.4932, lr: 0.0172\n",
      "episode: 153.00, total step: 23130.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.4068, lr: 0.0172\n",
      "episode: 154.00, total step: 23329.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.3651, lr: 0.0171\n",
      "episode: 155.00, total step: 23528.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.3705, lr: 0.0171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MR.Mohebbian\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 156.00, total step: 23727.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.4229, lr: 0.0171\n",
      "episode: 157.00, total step: 23926.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.4336, lr: 0.0171\n",
      "episode: 158.00, total step: 24125.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.4018, lr: 0.0171\n",
      "episode: 159.00, total step: 24252.00, last_episode length: 127.00, last_episode_reward: 126.00, loss: -0.3216, lr: 0.0171\n",
      "episode: 160.00, total step: 24451.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.2478, lr: 0.0170\n",
      "episode: 161.00, total step: 24650.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.3192, lr: 0.0170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MR.Mohebbian\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 162.00, total step: 24849.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.4448, lr: 0.0170\n",
      "episode: 163.00, total step: 25048.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.3910, lr: 0.0170\n",
      "episode: 164.00, total step: 25247.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.3736, lr: 0.0170\n",
      "episode: 165.00, total step: 25446.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.3762, lr: 0.0170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MR.Mohebbian\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 166.00, total step: 25645.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.5162, lr: 0.0169\n",
      "episode: 167.00, total step: 25844.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.5874, lr: 0.0169\n",
      "episode: 168.00, total step: 26043.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.5027, lr: 0.0169\n",
      "episode: 169.00, total step: 26179.00, last_episode length: 136.00, last_episode_reward: 135.00, loss: -0.5450, lr: 0.0169\n",
      "episode: 170.00, total step: 26378.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.4495, lr: 0.0169\n",
      "episode: 171.00, total step: 26577.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.5156, lr: 0.0169\n",
      "episode: 172.00, total step: 26776.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.3752, lr: 0.0168"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MR.Mohebbian\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "episode: 173.00, total step: 26884.00, last_episode length: 108.00, last_episode_reward: 107.00, loss: -0.3045, lr: 0.0168\n",
      "episode: 174.00, total step: 27083.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.2300, lr: 0.0168\n",
      "episode: 175.00, total step: 27282.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.3041, lr: 0.0168\n",
      "episode: 176.00, total step: 27481.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.3915, lr: 0.0168\n",
      "episode: 177.00, total step: 27680.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.3582, lr: 0.0168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MR.Mohebbian\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 178.00, total step: 27879.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.3320, lr: 0.0167\n",
      "episode: 179.00, total step: 28078.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.3062, lr: 0.0167\n",
      "episode: 180.00, total step: 28277.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.3616, lr: 0.0167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MR.Mohebbian\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 181.00, total step: 28476.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.3331, lr: 0.0167\n",
      "episode: 182.00, total step: 28675.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: 0.2685, lr: 0.0167\n",
      "episode: 183.00, total step: 28874.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.0857, lr: 0.0167\n",
      "episode: 184.00, total step: 29073.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.4255, lr: 0.0166\n",
      "episode: 185.00, total step: 29272.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.3249, lr: 0.0166\n",
      "episode: 186.00, total step: 29471.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.3685, lr: 0.0166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MR.Mohebbian\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 187.00, total step: 29670.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.5914, lr: 0.0166\n",
      "episode: 188.00, total step: 29869.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.5533, lr: 0.0166\n",
      "episode: 189.00, total step: 29981.00, last_episode length: 112.00, last_episode_reward: 111.00, loss: -0.3459, lr: 0.0166\n",
      "episode: 190.00, total step: 30180.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.2421, lr: 0.0165\n",
      "episode: 191.00, total step: 30303.00, last_episode length: 123.00, last_episode_reward: 122.00, loss: -0.1751, lr: 0.0165\n",
      "episode: 192.00, total step: 30486.00, last_episode length: 183.00, last_episode_reward: 182.00, loss: -0.3376, lr: 0.0165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MR.Mohebbian\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 193.00, total step: 30685.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.3389, lr: 0.0165\n",
      "episode: 194.00, total step: 30884.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.5338, lr: 0.0165\n",
      "episode: 195.00, total step: 31013.00, last_episode length: 129.00, last_episode_reward: 128.00, loss: -0.3856, lr: 0.0165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MR.Mohebbian\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 196.00, total step: 31212.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.2784, lr: 0.0164\n",
      "episode: 197.00, total step: 31411.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.2869, lr: 0.0164\n",
      "episode: 198.00, total step: 31610.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.3867, lr: 0.0164\n",
      "episode: 199.00, total step: 31809.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.2057, lr: 0.0164\n",
      "episode: 200.00, total step: 32008.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.1606, lr: 0.0164\n",
      "episode: 201.00, total step: 32207.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.1954, lr: 0.0164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MR.Mohebbian\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 202.00, total step: 32406.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.4137, lr: 0.0163\n",
      "episode: 203.00, total step: 32605.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.4145, lr: 0.0163\n",
      "episode: 204.00, total step: 32744.00, last_episode length: 139.00, last_episode_reward: 138.00, loss: -0.1995, lr: 0.0163\n",
      "episode: 205.00, total step: 32943.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.1076, lr: 0.0163\n",
      "episode: 206.00, total step: 33142.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.2135, lr: 0.0163\n",
      "episode: 207.00, total step: 33341.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.5368, lr: 0.0163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MR.Mohebbian\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 208.00, total step: 33540.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.4454, lr: 0.0162\n",
      "episode: 209.00, total step: 33739.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.2517, lr: 0.0162\n",
      "episode: 210.00, total step: 33938.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.3281, lr: 0.0162\n",
      "episode: 211.00, total step: 34137.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.3333, lr: 0.0162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MR.Mohebbian\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 212.00, total step: 34336.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.2358, lr: 0.0162\n",
      "episode: 213.00, total step: 34535.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.2136, lr: 0.0162\n",
      "episode: 214.00, total step: 34734.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.2351, lr: 0.0161\n",
      "episode: 215.00, total step: 34933.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.4061, lr: 0.0161\n",
      "episode: 216.00, total step: 35132.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.3956, lr: 0.0161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MR.Mohebbian\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 217.00, total step: 35261.00, last_episode length: 129.00, last_episode_reward: 128.00, loss: -0.4441, lr: 0.0161\n",
      "episode: 218.00, total step: 35460.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.3891, lr: 0.0161\n",
      "episode: 219.00, total step: 35659.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.6337, lr: 0.0161\n",
      "episode: 220.00, total step: 35858.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.6657, lr: 0.0160\n",
      "episode: 221.00, total step: 36057.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.4799, lr: 0.0160\n",
      "episode: 222.00, total step: 36256.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.4458, lr: 0.0160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MR.Mohebbian\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 223.00, total step: 36455.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.4377, lr: 0.0160\n",
      "episode: 224.00, total step: 36654.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.2928, lr: 0.0160\n",
      "episode: 225.00, total step: 36800.00, last_episode length: 146.00, last_episode_reward: 145.00, loss: -0.2530, lr: 0.0160\n",
      "episode: 226.00, total step: 36999.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.3208, lr: 0.0160\n",
      "episode: 227.00, total step: 37198.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.5168, lr: 0.0159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MR.Mohebbian\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 228.00, total step: 37381.00, last_episode length: 183.00, last_episode_reward: 182.00, loss: -0.4638, lr: 0.0159\n",
      "episode: 229.00, total step: 37536.00, last_episode length: 155.00, last_episode_reward: 154.00, loss: -0.4681, lr: 0.0159\n",
      "episode: 230.00, total step: 37735.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.4553, lr: 0.0159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MR.Mohebbian\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 231.00, total step: 37934.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.8338, lr: 0.0159\n",
      "episode: 232.00, total step: 38133.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.5882, lr: 0.0159\n",
      "episode: 233.00, total step: 38332.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.4532, lr: 0.0158\n",
      "episode: 234.00, total step: 38531.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.4294, lr: 0.0158\n",
      "episode: 235.00, total step: 38730.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.2680, lr: 0.0158\n",
      "episode: 236.00, total step: 38840.00, last_episode length: 110.00, last_episode_reward: 109.00, loss: -0.1850, lr: 0.0158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MR.Mohebbian\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 237.00, total step: 39039.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.1557, lr: 0.0158\n",
      "episode: 238.00, total step: 39223.00, last_episode length: 184.00, last_episode_reward: 183.00, loss: -0.3075, lr: 0.0158\n",
      "episode: 239.00, total step: 39378.00, last_episode length: 155.00, last_episode_reward: 154.00, loss: -0.6483, lr: 0.0157\n",
      "episode: 240.00, total step: 39577.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.5630, lr: 0.0157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MR.Mohebbian\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 241.00, total step: 39776.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.4887, lr: 0.0157\n",
      "episode: 242.00, total step: 39975.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.3158, lr: 0.0157\n",
      "episode: 243.00, total step: 40174.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.4381, lr: 0.0157\n",
      "episode: 244.00, total step: 40373.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.4807, lr: 0.0157\n",
      "episode: 245.00, total step: 40572.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.3206, lr: 0.0157\n",
      "episode: 246.00, total step: 40771.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.1908, lr: 0.0156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MR.Mohebbian\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 247.00, total step: 40970.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.3363, lr: 0.0156\n",
      "episode: 248.00, total step: 41072.00, last_episode length: 102.00, last_episode_reward: 101.00, loss: -0.3560, lr: 0.0156\n",
      "episode: 249.00, total step: 41271.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.3120, lr: 0.0156\n",
      "episode: 250.00, total step: 41435.00, last_episode length: 164.00, last_episode_reward: 163.00, loss: -0.3648, lr: 0.0156\n",
      "episode: 251.00, total step: 41613.00, last_episode length: 178.00, last_episode_reward: 177.00, loss: -0.6639, lr: 0.0156\n",
      "episode: 252.00, total step: 41812.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.6916, lr: 0.0155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MR.Mohebbian\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 253.00, total step: 42011.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.4412, lr: 0.0155\n",
      "episode: 254.00, total step: 42210.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.1463, lr: 0.0155\n",
      "episode: 255.00, total step: 42409.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: 0.0038, lr: 0.0155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MR.Mohebbian\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 256.00, total step: 42608.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.1152, lr: 0.0155\n",
      "episode: 257.00, total step: 42807.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.3587, lr: 0.0155\n",
      "episode: 258.00, total step: 43006.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.5679, lr: 0.0154\n",
      "episode: 259.00, total step: 43133.00, last_episode length: 127.00, last_episode_reward: 126.00, loss: -0.3879, lr: 0.0154\n",
      "episode: 260.00, total step: 43332.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.4034, lr: 0.0154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MR.Mohebbian\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 261.00, total step: 43531.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.1664, lr: 0.0154\n",
      "episode: 262.00, total step: 43730.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.1715, lr: 0.0154\n",
      "episode: 263.00, total step: 43929.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.1135, lr: 0.0154\n",
      "episode: 264.00, total step: 44017.00, last_episode length: 88.00, last_episode_reward: 87.00, loss: -0.4560, lr: 0.0154\n",
      "episode: 265.00, total step: 44216.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.4595, lr: 0.0153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MR.Mohebbian\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 266.00, total step: 44415.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.6425, lr: 0.0153\n",
      "episode: 267.00, total step: 44510.00, last_episode length: 95.00, last_episode_reward: 94.00, loss: -0.4363, lr: 0.0153\n",
      "episode: 268.00, total step: 44709.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.4192, lr: 0.0153\n",
      "episode: 269.00, total step: 44844.00, last_episode length: 135.00, last_episode_reward: 134.00, loss: -0.1324, lr: 0.0153\n",
      "episode: 270.00, total step: 45043.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.3632, lr: 0.0153\n",
      "episode: 271.00, total step: 45242.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.2866, lr: 0.0153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MR.Mohebbian\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 272.00, total step: 45400.00, last_episode length: 158.00, last_episode_reward: 157.00, loss: -0.3859, lr: 0.0152\n",
      "episode: 273.00, total step: 45599.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.4342, lr: 0.0152\n",
      "episode: 274.00, total step: 45718.00, last_episode length: 119.00, last_episode_reward: 118.00, loss: -0.3626, lr: 0.0152\n",
      "episode: 275.00, total step: 45917.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.5142, lr: 0.0152\n",
      "episode: 276.00, total step: 46116.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.5278, lr: 0.0152\n",
      "episode: 277.00, total step: 46239.00, last_episode length: 123.00, last_episode_reward: 122.00, loss: -0.3769, lr: 0.0152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MR.Mohebbian\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 278.00, total step: 46438.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.4182, lr: 0.0151\n",
      "episode: 279.00, total step: 46637.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.4094, lr: 0.0151\n",
      "episode: 280.00, total step: 46836.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.5316, lr: 0.0151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MR.Mohebbian\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 281.00, total step: 47035.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.2570, lr: 0.0151\n",
      "episode: 282.00, total step: 47234.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.2870, lr: 0.0151\n",
      "episode: 283.00, total step: 47433.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.1971, lr: 0.0151\n",
      "episode: 284.00, total step: 47632.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.1325, lr: 0.0151\n",
      "episode: 285.00, total step: 47831.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.0702, lr: 0.0150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MR.Mohebbian\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 286.00, total step: 48030.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.2716, lr: 0.0150\n",
      "episode: 287.00, total step: 48150.00, last_episode length: 120.00, last_episode_reward: 119.00, loss: -0.5583, lr: 0.0150\n",
      "episode: 288.00, total step: 48349.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.6451, lr: 0.0150\n",
      "episode: 289.00, total step: 48464.00, last_episode length: 115.00, last_episode_reward: 114.00, loss: -0.3132, lr: 0.0150\n",
      "episode: 290.00, total step: 48663.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.3341, lr: 0.0150\n",
      "episode: 291.00, total step: 48762.00, last_episode length: 99.00, last_episode_reward: 98.00, loss: -0.3051, lr: 0.0149\n",
      "episode: 292.00, total step: 48873.00, last_episode length: 111.00, last_episode_reward: 110.00, loss: -0.6243, lr: 0.0149\n",
      "episode: 293.00, total step: 49070.00, last_episode length: 197.00, last_episode_reward: 196.00, loss: -0.6243, lr: 0.0149"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MR.Mohebbian\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "episode: 294.00, total step: 49269.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.5658, lr: 0.0149\n",
      "episode: 295.00, total step: 49468.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.5781, lr: 0.0149\n",
      "episode: 296.00, total step: 49605.00, last_episode length: 137.00, last_episode_reward: 136.00, loss: -0.0383, lr: 0.0149\n",
      "episode: 297.00, total step: 49804.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.0035, lr: 0.0149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MR.Mohebbian\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 298.00, total step: 50003.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.0631, lr: 0.0148\n",
      "episode: 299.00, total step: 50202.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.4522, lr: 0.0148\n",
      "episode: 300.00, total step: 50401.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.3797, lr: 0.0148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MR.Mohebbian\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 301.00, total step: 50600.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.7153, lr: 0.0148\n",
      "episode: 302.00, total step: 50799.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.7937, lr: 0.0148\n",
      "episode: 303.00, total step: 50998.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.4018, lr: 0.0148\n",
      "episode: 304.00, total step: 51107.00, last_episode length: 109.00, last_episode_reward: 108.00, loss: -0.2529, lr: 0.0148\n",
      "episode: 305.00, total step: 51306.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.1985, lr: 0.0147\n",
      "episode: 306.00, total step: 51505.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.5059, lr: 0.0147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MR.Mohebbian\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 307.00, total step: 51704.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.4398, lr: 0.0147\n",
      "episode: 308.00, total step: 51903.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.4569, lr: 0.0147\n",
      "episode: 309.00, total step: 52094.00, last_episode length: 191.00, last_episode_reward: 190.00, loss: -0.4318, lr: 0.0147\n",
      "episode: 310.00, total step: 52293.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.4749, lr: 0.0147\n",
      "episode: 311.00, total step: 52492.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.3536, lr: 0.0147\n",
      "episode: 312.00, total step: 52691.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.1425, lr: 0.0146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MR.Mohebbian\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 313.00, total step: 52890.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.2600, lr: 0.0146\n",
      "episode: 314.00, total step: 53089.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.6250, lr: 0.0146\n",
      "episode: 315.00, total step: 53215.00, last_episode length: 126.00, last_episode_reward: 125.00, loss: -0.4830, lr: 0.0146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MR.Mohebbian\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 316.00, total step: 53414.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.4877, lr: 0.0146\n",
      "episode: 317.00, total step: 53613.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.3070, lr: 0.0146\n",
      "episode: 318.00, total step: 53812.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.3298, lr: 0.0145\n",
      "episode: 319.00, total step: 54011.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.0674, lr: 0.0145\n",
      "episode: 320.00, total step: 54210.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.1330, lr: 0.0145\n",
      "episode: 321.00, total step: 54374.00, last_episode length: 164.00, last_episode_reward: 163.00, loss: -0.2795, lr: 0.0145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MR.Mohebbian\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 322.00, total step: 54573.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.2917, lr: 0.0145\n",
      "episode: 323.00, total step: 54772.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.5157, lr: 0.0145\n",
      "episode: 324.00, total step: 54923.00, last_episode length: 151.00, last_episode_reward: 150.00, loss: -0.4040, lr: 0.0145\n",
      "episode: 325.00, total step: 55122.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.4323, lr: 0.0144\n",
      "episode: 326.00, total step: 55321.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.3595, lr: 0.0144\n",
      "episode: 327.00, total step: 55520.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.4616, lr: 0.0144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MR.Mohebbian\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 328.00, total step: 55719.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.2177, lr: 0.0144\n",
      "episode: 329.00, total step: 55918.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.0651, lr: 0.0144\n",
      "episode: 330.00, total step: 56117.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: 0.0162, lr: 0.0144\n",
      "episode: 331.00, total step: 56316.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.0348, lr: 0.0144\n",
      "episode: 332.00, total step: 56515.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.0138, lr: 0.0143"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MR.Mohebbian\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "episode: 333.00, total step: 56690.00, last_episode length: 175.00, last_episode_reward: 174.00, loss: -0.4633, lr: 0.0143\n",
      "episode: 334.00, total step: 56889.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.5652, lr: 0.0143\n",
      "episode: 335.00, total step: 57088.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.5784, lr: 0.0143\n",
      "episode: 336.00, total step: 57211.00, last_episode length: 123.00, last_episode_reward: 122.00, loss: -0.5331, lr: 0.0143\n",
      "episode: 337.00, total step: 57410.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.5182, lr: 0.0143"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MR.Mohebbian\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "episode: 338.00, total step: 57609.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.6965, lr: 0.0143\n",
      "episode: 339.00, total step: 57808.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.5113, lr: 0.0142\n",
      "episode: 340.00, total step: 58007.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.2938, lr: 0.0142\n",
      "episode: 341.00, total step: 58206.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.6118, lr: 0.0142\n",
      "episode: 342.00, total step: 58405.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.6241, lr: 0.0142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MR.Mohebbian\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 343.00, total step: 58604.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.2977, lr: 0.0142\n",
      "episode: 344.00, total step: 58803.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.3705, lr: 0.0142\n",
      "episode: 345.00, total step: 59002.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.2785, lr: 0.0142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MR.Mohebbian\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 346.00, total step: 59201.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.1874, lr: 0.0141\n",
      "episode: 347.00, total step: 59400.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.1040, lr: 0.0141\n",
      "episode: 348.00, total step: 59599.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.1181, lr: 0.0141\n",
      "episode: 349.00, total step: 59798.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.5356, lr: 0.0141\n",
      "episode: 350.00, total step: 59952.00, last_episode length: 154.00, last_episode_reward: 153.00, loss: -0.8558, lr: 0.0141\n",
      "episode: 351.00, total step: 60151.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.7949, lr: 0.0141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MR.Mohebbian\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 352.00, total step: 60350.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.5050, lr: 0.0141\n",
      "episode: 353.00, total step: 60549.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.6329, lr: 0.0140\n",
      "episode: 354.00, total step: 60748.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.5018, lr: 0.0140\n",
      "episode: 355.00, total step: 60947.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: 0.0197, lr: 0.0140\n",
      "episode: 356.00, total step: 61146.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.4046, lr: 0.0140\n",
      "episode: 357.00, total step: 61345.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.7791, lr: 0.0140"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MR.Mohebbian\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "episode: 358.00, total step: 61544.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.1917, lr: 0.0140\n",
      "episode: 359.00, total step: 61668.00, last_episode length: 124.00, last_episode_reward: 123.00, loss: 0.6211, lr: 0.0140\n",
      "episode: 360.00, total step: 61810.00, last_episode length: 142.00, last_episode_reward: 141.00, loss: -0.2326, lr: 0.0140\n",
      "episode: 361.00, total step: 62009.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.3378, lr: 0.0139\n",
      "episode: 362.00, total step: 62136.00, last_episode length: 127.00, last_episode_reward: 126.00, loss: -0.7041, lr: 0.0139"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MR.Mohebbian\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "episode: 363.00, total step: 62335.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.7096, lr: 0.0139\n",
      "episode: 364.00, total step: 62534.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.6935, lr: 0.0139\n",
      "episode: 365.00, total step: 62688.00, last_episode length: 154.00, last_episode_reward: 153.00, loss: -0.8301, lr: 0.0139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MR.Mohebbian\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 366.00, total step: 62887.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.7927, lr: 0.0139\n",
      "episode: 367.00, total step: 63086.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.7897, lr: 0.0139\n",
      "episode: 368.00, total step: 63285.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.8278, lr: 0.0138\n",
      "episode: 369.00, total step: 63484.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.5392, lr: 0.0138\n",
      "episode: 370.00, total step: 63623.00, last_episode length: 139.00, last_episode_reward: 138.00, loss: -0.4067, lr: 0.0138\n",
      "episode: 371.00, total step: 63822.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.3810, lr: 0.0138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MR.Mohebbian\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 372.00, total step: 64021.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.4926, lr: 0.0138\n",
      "episode: 373.00, total step: 64220.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.6192, lr: 0.0138\n",
      "episode: 374.00, total step: 64419.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.5882, lr: 0.0138\n",
      "episode: 375.00, total step: 64618.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.4206, lr: 0.0137\n",
      "episode: 376.00, total step: 64817.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.2487, lr: 0.0137\n",
      "episode: 377.00, total step: 65016.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.2744, lr: 0.0137"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MR.Mohebbian\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "episode: 378.00, total step: 65215.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.4687, lr: 0.0137\n",
      "episode: 379.00, total step: 65414.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.3597, lr: 0.0137\n",
      "episode: 380.00, total step: 65613.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.1140, lr: 0.0137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MR.Mohebbian\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 381.00, total step: 65812.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.3919, lr: 0.0137\n",
      "episode: 382.00, total step: 66011.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.7736, lr: 0.0136\n",
      "episode: 383.00, total step: 66210.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.6555, lr: 0.0136\n",
      "episode: 384.00, total step: 66409.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.2848, lr: 0.0136\n",
      "episode: 385.00, total step: 66608.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.3891, lr: 0.0136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MR.Mohebbian\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 386.00, total step: 66807.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.3440, lr: 0.0136\n",
      "episode: 387.00, total step: 67006.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.0936, lr: 0.0136\n",
      "episode: 388.00, total step: 67205.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.3250, lr: 0.0136\n",
      "episode: 389.00, total step: 67404.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.4636, lr: 0.0136\n",
      "episode: 390.00, total step: 67603.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.2176, lr: 0.0135\n",
      "episode: 391.00, total step: 67757.00, last_episode length: 154.00, last_episode_reward: 153.00, loss: -0.0913, lr: 0.0135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MR.Mohebbian\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 392.00, total step: 67956.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.2289, lr: 0.0135\n",
      "episode: 393.00, total step: 68155.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.3183, lr: 0.0135\n",
      "episode: 394.00, total step: 68354.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.2119, lr: 0.0135\n",
      "episode: 395.00, total step: 68536.00, last_episode length: 182.00, last_episode_reward: 181.00, loss: -0.1638, lr: 0.0135\n",
      "episode: 396.00, total step: 68735.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.3248, lr: 0.0135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MR.Mohebbian\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 397.00, total step: 68934.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.6062, lr: 0.0134\n",
      "episode: 398.00, total step: 69133.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.4242, lr: 0.0134\n",
      "episode: 399.00, total step: 69265.00, last_episode length: 132.00, last_episode_reward: 131.00, loss: -0.2234, lr: 0.0134\n",
      "episode: 400.00, total step: 69464.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.2636, lr: 0.0134\n",
      "episode: 401.00, total step: 69663.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.2314, lr: 0.0134\n",
      "episode: 402.00, total step: 69813.00, last_episode length: 150.00, last_episode_reward: 149.00, loss: -0.1674, lr: 0.0134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MR.Mohebbian\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 403.00, total step: 69957.00, last_episode length: 144.00, last_episode_reward: 143.00, loss: -0.2238, lr: 0.0134\n",
      "episode: 404.00, total step: 70156.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.5447, lr: 0.0134\n",
      "episode: 405.00, total step: 70355.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.6623, lr: 0.0133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MR.Mohebbian\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 406.00, total step: 70554.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.5182, lr: 0.0133\n",
      "episode: 407.00, total step: 70680.00, last_episode length: 126.00, last_episode_reward: 125.00, loss: -0.4883, lr: 0.0133\n",
      "episode: 408.00, total step: 70879.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.5506, lr: 0.0133\n",
      "episode: 409.00, total step: 71078.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.6400, lr: 0.0133\n",
      "episode: 410.00, total step: 71277.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.2273, lr: 0.0133\n",
      "episode: 411.00, total step: 71476.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.1591, lr: 0.0133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MR.Mohebbian\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 412.00, total step: 71675.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.4439, lr: 0.0132\n",
      "episode: 413.00, total step: 71874.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.4574, lr: 0.0132\n",
      "episode: 414.00, total step: 72014.00, last_episode length: 140.00, last_episode_reward: 139.00, loss: -0.3033, lr: 0.0132\n",
      "episode: 415.00, total step: 72213.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.2926, lr: 0.0132\n",
      "episode: 416.00, total step: 72351.00, last_episode length: 138.00, last_episode_reward: 137.00, loss: -0.3974, lr: 0.0132\n",
      "episode: 417.00, total step: 72544.00, last_episode length: 193.00, last_episode_reward: 192.00, loss: -0.5994, lr: 0.0132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MR.Mohebbian\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 418.00, total step: 72743.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.6522, lr: 0.0132\n",
      "episode: 419.00, total step: 72942.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.5905, lr: 0.0132\n",
      "episode: 420.00, total step: 73141.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.5783, lr: 0.0131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MR.Mohebbian\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 421.00, total step: 73340.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.4888, lr: 0.0131\n",
      "episode: 422.00, total step: 73539.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.5487, lr: 0.0131\n",
      "episode: 423.00, total step: 73738.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.3445, lr: 0.0131\n",
      "episode: 424.00, total step: 73937.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.3125, lr: 0.0131\n",
      "episode: 425.00, total step: 74136.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.3540, lr: 0.0131\n",
      "episode: 426.00, total step: 74335.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.4007, lr: 0.0131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MR.Mohebbian\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 427.00, total step: 74534.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.4082, lr: 0.0130\n",
      "episode: 428.00, total step: 74733.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.1353, lr: 0.0130\n",
      "episode: 429.00, total step: 74932.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.1593, lr: 0.0130\n",
      "episode: 430.00, total step: 75131.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.3163, lr: 0.0130\n",
      "episode: 431.00, total step: 75330.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.2326, lr: 0.0130\n",
      "episode: 432.00, total step: 75529.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.2200, lr: 0.0130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MR.Mohebbian\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 433.00, total step: 75728.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.2043, lr: 0.0130\n",
      "episode: 434.00, total step: 75927.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.1552, lr: 0.0130\n",
      "episode: 435.00, total step: 76126.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.3491, lr: 0.0129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MR.Mohebbian\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 436.00, total step: 76325.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.4465, lr: 0.0129\n",
      "episode: 437.00, total step: 76524.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.2177, lr: 0.0129\n",
      "episode: 438.00, total step: 76723.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.2610, lr: 0.0129\n",
      "episode: 439.00, total step: 76922.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.4992, lr: 0.0129\n",
      "episode: 440.00, total step: 77121.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.5750, lr: 0.0129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MR.Mohebbian\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 441.00, total step: 77320.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.4398, lr: 0.0129\n",
      "episode: 442.00, total step: 77519.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.3214, lr: 0.0129\n",
      "episode: 443.00, total step: 77718.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.4411, lr: 0.0128\n",
      "episode: 444.00, total step: 77856.00, last_episode length: 138.00, last_episode_reward: 137.00, loss: -0.6037, lr: 0.0128\n",
      "episode: 445.00, total step: 78055.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.6976, lr: 0.0128\n",
      "episode: 446.00, total step: 78254.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.2887, lr: 0.0128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MR.Mohebbian\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 447.00, total step: 78453.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.1724, lr: 0.0128\n",
      "episode: 448.00, total step: 78652.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.2269, lr: 0.0128\n",
      "episode: 449.00, total step: 78851.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.1527, lr: 0.0128\n",
      "episode: 450.00, total step: 79050.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.3908, lr: 0.0127\n",
      "episode: 451.00, total step: 79249.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.4024, lr: 0.0127\n",
      "episode: 452.00, total step: 79425.00, last_episode length: 176.00, last_episode_reward: 175.00, loss: -0.1968, lr: 0.0127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MR.Mohebbian\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 453.00, total step: 79624.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.3345, lr: 0.0127\n",
      "episode: 454.00, total step: 79823.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.3153, lr: 0.0127\n",
      "episode: 455.00, total step: 80007.00, last_episode length: 184.00, last_episode_reward: 183.00, loss: -0.5746, lr: 0.0127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MR.Mohebbian\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 456.00, total step: 80206.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.7130, lr: 0.0127\n",
      "episode: 457.00, total step: 80405.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.4922, lr: 0.0127\n",
      "episode: 458.00, total step: 80604.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.2056, lr: 0.0126\n",
      "episode: 459.00, total step: 80803.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.3315, lr: 0.0126\n",
      "episode: 460.00, total step: 80967.00, last_episode length: 164.00, last_episode_reward: 163.00, loss: -0.3080, lr: 0.0126\n",
      "episode: 461.00, total step: 81130.00, last_episode length: 163.00, last_episode_reward: 162.00, loss: -0.3873, lr: 0.0126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MR.Mohebbian\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 462.00, total step: 81274.00, last_episode length: 144.00, last_episode_reward: 143.00, loss: -0.5964, lr: 0.0126\n",
      "episode: 463.00, total step: 81473.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.8393, lr: 0.0126\n",
      "episode: 464.00, total step: 81672.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.5460, lr: 0.0126\n",
      "episode: 465.00, total step: 81843.00, last_episode length: 171.00, last_episode_reward: 170.00, loss: -0.4566, lr: 0.0126\n",
      "episode: 466.00, total step: 82042.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.5251, lr: 0.0125\n",
      "episode: 467.00, total step: 82241.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.6408, lr: 0.0125"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MR.Mohebbian\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "episode: 468.00, total step: 82440.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.4231, lr: 0.0125\n",
      "episode: 469.00, total step: 82639.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.1076, lr: 0.0125\n",
      "episode: 470.00, total step: 82838.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.2305, lr: 0.0125\n",
      "episode: 471.00, total step: 83037.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.4147, lr: 0.0125\n",
      "episode: 472.00, total step: 83236.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.3957, lr: 0.0125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MR.Mohebbian\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 473.00, total step: 83435.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.5573, lr: 0.0125\n",
      "episode: 474.00, total step: 83634.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.4626, lr: 0.0124\n",
      "episode: 475.00, total step: 83816.00, last_episode length: 182.00, last_episode_reward: 181.00, loss: -0.3554, lr: 0.0124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MR.Mohebbian\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 476.00, total step: 84015.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.5008, lr: 0.0124\n",
      "episode: 477.00, total step: 84214.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.6507, lr: 0.0124\n",
      "episode: 478.00, total step: 84413.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.5661, lr: 0.0124\n",
      "episode: 479.00, total step: 84612.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.5976, lr: 0.0124\n",
      "episode: 480.00, total step: 84811.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.5533, lr: 0.0124\n",
      "episode: 481.00, total step: 85010.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.3497, lr: 0.0124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MR.Mohebbian\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 482.00, total step: 85209.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.4500, lr: 0.0123\n",
      "episode: 483.00, total step: 85368.00, last_episode length: 159.00, last_episode_reward: 158.00, loss: -0.6749, lr: 0.0123\n",
      "episode: 484.00, total step: 85567.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.7085, lr: 0.0123\n",
      "episode: 485.00, total step: 85766.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.5010, lr: 0.0123\n",
      "episode: 486.00, total step: 85965.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.3485, lr: 0.0123\n",
      "episode: 487.00, total step: 86164.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.2443, lr: 0.0123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MR.Mohebbian\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 488.00, total step: 86363.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.4286, lr: 0.0123\n",
      "episode: 489.00, total step: 86562.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.4506, lr: 0.0123\n",
      "episode: 490.00, total step: 86761.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.5254, lr: 0.0122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MR.Mohebbian\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 491.00, total step: 86960.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.6792, lr: 0.0122\n",
      "episode: 492.00, total step: 87159.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.6806, lr: 0.0122\n",
      "episode: 493.00, total step: 87344.00, last_episode length: 185.00, last_episode_reward: 184.00, loss: -0.7465, lr: 0.0122\n",
      "episode: 494.00, total step: 87543.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.7415, lr: 0.0122\n",
      "episode: 495.00, total step: 87742.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.5380, lr: 0.0122\n",
      "episode: 496.00, total step: 87941.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.2641, lr: 0.0122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MR.Mohebbian\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 497.00, total step: 88140.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.1955, lr: 0.0122\n",
      "episode: 498.00, total step: 88339.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.1460, lr: 0.0122\n",
      "episode: 499.00, total step: 88538.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.2418, lr: 0.0121\n",
      "episode: 500.00, total step: 88737.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.3330, lr: 0.0121\n",
      "episode: 501.00, total step: 88936.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.4976, lr: 0.0121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MR.Mohebbian\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 502.00, total step: 89135.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.4527, lr: 0.0121\n",
      "episode: 503.00, total step: 89334.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.4157, lr: 0.0121\n",
      "episode: 504.00, total step: 89533.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.3355, lr: 0.0121\n",
      "episode: 505.00, total step: 89732.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.3213, lr: 0.0121\n",
      "episode: 506.00, total step: 89931.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.6165, lr: 0.0121\n",
      "episode: 507.00, total step: 90130.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.6194, lr: 0.0120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MR.Mohebbian\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 508.00, total step: 90329.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.6372, lr: 0.0120\n",
      "episode: 509.00, total step: 90528.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.6550, lr: 0.0120\n",
      "episode: 510.00, total step: 90727.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.5114, lr: 0.0120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MR.Mohebbian\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 511.00, total step: 90900.00, last_episode length: 173.00, last_episode_reward: 172.00, loss: -0.5985, lr: 0.0120\n",
      "episode: 512.00, total step: 91099.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.6197, lr: 0.0120\n",
      "episode: 513.00, total step: 91298.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.5060, lr: 0.0120\n",
      "episode: 514.00, total step: 91497.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.3956, lr: 0.0120\n",
      "episode: 515.00, total step: 91696.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.5062, lr: 0.0119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MR.Mohebbian\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 516.00, total step: 91895.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.4450, lr: 0.0119\n",
      "episode: 517.00, total step: 92094.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.4196, lr: 0.0119\n",
      "episode: 518.00, total step: 92293.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.5137, lr: 0.0119\n",
      "episode: 519.00, total step: 92492.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.5794, lr: 0.0119\n",
      "episode: 520.00, total step: 92653.00, last_episode length: 161.00, last_episode_reward: 160.00, loss: -0.4755, lr: 0.0119\n",
      "episode: 521.00, total step: 92820.00, last_episode length: 167.00, last_episode_reward: 166.00, loss: -0.4761, lr: 0.0119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MR.Mohebbian\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 522.00, total step: 93015.00, last_episode length: 195.00, last_episode_reward: 194.00, loss: -0.6552, lr: 0.0119\n",
      "episode: 523.00, total step: 93201.00, last_episode length: 186.00, last_episode_reward: 185.00, loss: -0.7636, lr: 0.0119\n",
      "episode: 524.00, total step: 93400.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.7119, lr: 0.0118\n",
      "episode: 525.00, total step: 93599.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.4399, lr: 0.0118\n",
      "episode: 526.00, total step: 93798.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.3004, lr: 0.0118\n",
      "episode: 527.00, total step: 93997.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.2085, lr: 0.0118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MR.Mohebbian\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 528.00, total step: 94196.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.2423, lr: 0.0118\n",
      "episode: 529.00, total step: 94395.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.3859, lr: 0.0118\n",
      "episode: 530.00, total step: 94594.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.3519, lr: 0.0118\n",
      "episode: 531.00, total step: 94793.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.2549, lr: 0.0118\n",
      "episode: 532.00, total step: 94992.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.4193, lr: 0.0117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MR.Mohebbian\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 533.00, total step: 95191.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.7854, lr: 0.0117\n",
      "episode: 534.00, total step: 95390.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.9764, lr: 0.0117\n",
      "episode: 535.00, total step: 95567.00, last_episode length: 177.00, last_episode_reward: 176.00, loss: -0.8916, lr: 0.0117\n",
      "episode: 536.00, total step: 95766.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.7613, lr: 0.0117\n",
      "episode: 537.00, total step: 95965.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.3688, lr: 0.0117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MR.Mohebbian\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 538.00, total step: 96164.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.0250, lr: 0.0117\n",
      "episode: 539.00, total step: 96363.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.2595, lr: 0.0117\n",
      "episode: 540.00, total step: 96562.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.5794, lr: 0.0117\n",
      "episode: 541.00, total step: 96761.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.8361, lr: 0.0116\n",
      "episode: 542.00, total step: 96960.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.8286, lr: 0.0116"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MR.Mohebbian\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "episode: 543.00, total step: 97159.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.4466, lr: 0.0116\n",
      "episode: 544.00, total step: 97358.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.3999, lr: 0.0116\n",
      "episode: 545.00, total step: 97557.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.4495, lr: 0.0116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MR.Mohebbian\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 546.00, total step: 97756.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.2784, lr: 0.0116\n",
      "episode: 547.00, total step: 97955.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.2313, lr: 0.0116\n",
      "episode: 548.00, total step: 98154.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.1993, lr: 0.0116\n",
      "episode: 549.00, total step: 98353.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.2515, lr: 0.0115\n",
      "episode: 550.00, total step: 98552.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.6135, lr: 0.0115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MR.Mohebbian\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 551.00, total step: 98751.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.7279, lr: 0.0115\n",
      "episode: 552.00, total step: 98897.00, last_episode length: 146.00, last_episode_reward: 145.00, loss: -0.4013, lr: 0.0115\n",
      "episode: 553.00, total step: 99034.00, last_episode length: 137.00, last_episode_reward: 136.00, loss: -0.3836, lr: 0.0115\n",
      "episode: 554.00, total step: 99233.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.4369, lr: 0.0115\n",
      "episode: 555.00, total step: 99432.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.4987, lr: 0.0115\n",
      "episode: 556.00, total step: 99631.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.4650, lr: 0.0115\n",
      "episode: 557.00, total step: 99771.00, last_episode length: 140.00, last_episode_reward: 139.00, loss: -0.5896, lr: 0.0115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MR.Mohebbian\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 558.00, total step: 99970.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.5452, lr: 0.0114\n",
      "episode: 559.00, total step: 100169.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.6827, lr: 0.0114\n",
      "episode: 560.00, total step: 100368.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.5374, lr: 0.0114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MR.Mohebbian\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 561.00, total step: 100520.00, last_episode length: 152.00, last_episode_reward: 151.00, loss: -0.3176, lr: 0.0114\n",
      "episode: 562.00, total step: 100719.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.2730, lr: 0.0114\n",
      "episode: 563.00, total step: 100918.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.4871, lr: 0.0114\n",
      "episode: 564.00, total step: 101117.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.7833, lr: 0.0114\n",
      "episode: 565.00, total step: 101281.00, last_episode length: 164.00, last_episode_reward: 163.00, loss: -0.6342, lr: 0.0114\n",
      "episode: 566.00, total step: 101480.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.5239, lr: 0.0114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MR.Mohebbian\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 567.00, total step: 101679.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.6011, lr: 0.0113\n",
      "episode: 568.00, total step: 101878.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.6533, lr: 0.0113\n",
      "episode: 569.00, total step: 102077.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.2402, lr: 0.0113\n",
      "episode: 570.00, total step: 102276.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.0613, lr: 0.0113\n",
      "episode: 571.00, total step: 102475.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.4243, lr: 0.0113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MR.Mohebbian\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 572.00, total step: 102674.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.4966, lr: 0.0113\n",
      "episode: 573.00, total step: 102873.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.3122, lr: 0.0113\n",
      "episode: 574.00, total step: 103011.00, last_episode length: 138.00, last_episode_reward: 137.00, loss: -0.2420, lr: 0.0113\n",
      "episode: 575.00, total step: 103210.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.1769, lr: 0.0113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MR.Mohebbian\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 576.00, total step: 103409.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.2269, lr: 0.0112\n",
      "episode: 577.00, total step: 103608.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.3347, lr: 0.0112\n",
      "episode: 578.00, total step: 103769.00, last_episode length: 161.00, last_episode_reward: 160.00, loss: -0.2908, lr: 0.0112\n",
      "episode: 579.00, total step: 103968.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.3628, lr: 0.0112\n",
      "episode: 580.00, total step: 104106.00, last_episode length: 138.00, last_episode_reward: 137.00, loss: -0.5712, lr: 0.0112\n",
      "episode: 581.00, total step: 104249.00, last_episode length: 143.00, last_episode_reward: 142.00, loss: -0.6263, lr: 0.0112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MR.Mohebbian\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 582.00, total step: 104448.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.6062, lr: 0.0112\n",
      "episode: 583.00, total step: 104647.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.6445, lr: 0.0112\n",
      "episode: 584.00, total step: 104846.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.4850, lr: 0.0112\n",
      "episode: 585.00, total step: 105045.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.2949, lr: 0.0111\n",
      "episode: 586.00, total step: 105244.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.3857, lr: 0.0111\n",
      "episode: 587.00, total step: 105443.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.6242, lr: 0.0111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MR.Mohebbian\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 588.00, total step: 105642.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.6317, lr: 0.0111\n",
      "episode: 589.00, total step: 105780.00, last_episode length: 138.00, last_episode_reward: 137.00, loss: -0.3946, lr: 0.0111\n",
      "episode: 590.00, total step: 105979.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.3169, lr: 0.0111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MR.Mohebbian\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 591.00, total step: 106178.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.4730, lr: 0.0111\n",
      "episode: 592.00, total step: 106351.00, last_episode length: 173.00, last_episode_reward: 172.00, loss: -0.6994, lr: 0.0111\n",
      "episode: 593.00, total step: 106550.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.5714, lr: 0.0111\n",
      "episode: 594.00, total step: 106749.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.6026, lr: 0.0110\n",
      "episode: 595.00, total step: 106948.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.5741, lr: 0.0110\n",
      "episode: 596.00, total step: 107083.00, last_episode length: 135.00, last_episode_reward: 134.00, loss: -0.3117, lr: 0.0110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MR.Mohebbian\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 597.00, total step: 107282.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.2761, lr: 0.0110\n",
      "episode: 598.00, total step: 107481.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.3839, lr: 0.0110\n",
      "episode: 599.00, total step: 107654.00, last_episode length: 173.00, last_episode_reward: 172.00, loss: -0.7491, lr: 0.0110\n",
      "episode: 600.00, total step: 107853.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.6286, lr: 0.0110\n",
      "episode: 601.00, total step: 107974.00, last_episode length: 121.00, last_episode_reward: 120.00, loss: -0.6211, lr: 0.0110\n",
      "episode: 602.00, total step: 108110.00, last_episode length: 136.00, last_episode_reward: 135.00, loss: -0.6116, lr: 0.0110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MR.Mohebbian\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 603.00, total step: 108309.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.6553, lr: 0.0109\n",
      "episode: 604.00, total step: 108508.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.5131, lr: 0.0109\n",
      "episode: 605.00, total step: 108707.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.4178, lr: 0.0109\n",
      "episode: 606.00, total step: 108906.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.4535, lr: 0.0109\n",
      "episode: 607.00, total step: 109069.00, last_episode length: 163.00, last_episode_reward: 162.00, loss: -0.3878, lr: 0.0109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MR.Mohebbian\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 608.00, total step: 109268.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.3920, lr: 0.0109\n",
      "episode: 609.00, total step: 109467.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.1789, lr: 0.0109\n",
      "episode: 610.00, total step: 109666.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.1473, lr: 0.0109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MR.Mohebbian\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 611.00, total step: 109865.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.3222, lr: 0.0109\n",
      "episode: 612.00, total step: 110064.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.6320, lr: 0.0108\n",
      "episode: 613.00, total step: 110233.00, last_episode length: 169.00, last_episode_reward: 168.00, loss: -0.6005, lr: 0.0108\n",
      "episode: 614.00, total step: 110432.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.5365, lr: 0.0108\n",
      "episode: 615.00, total step: 110631.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.4450, lr: 0.0108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MR.Mohebbian\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 616.00, total step: 110830.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.4963, lr: 0.0108\n",
      "episode: 617.00, total step: 111029.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.4086, lr: 0.0108\n",
      "episode: 618.00, total step: 111218.00, last_episode length: 189.00, last_episode_reward: 188.00, loss: -0.6283, lr: 0.0108\n",
      "episode: 619.00, total step: 111417.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.6772, lr: 0.0108\n",
      "episode: 620.00, total step: 111592.00, last_episode length: 175.00, last_episode_reward: 174.00, loss: -0.3943, lr: 0.0108\n",
      "episode: 621.00, total step: 111791.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.3714, lr: 0.0107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MR.Mohebbian\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 622.00, total step: 111990.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.3185, lr: 0.0107\n",
      "episode: 623.00, total step: 112189.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.2764, lr: 0.0107\n",
      "episode: 624.00, total step: 112388.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.1380, lr: 0.0107\n",
      "episode: 625.00, total step: 112587.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.2395, lr: 0.0107\n",
      "episode: 626.00, total step: 112786.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.4848, lr: 0.0107\n",
      "episode: 627.00, total step: 112945.00, last_episode length: 159.00, last_episode_reward: 158.00, loss: -0.3777, lr: 0.0107"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MR.Mohebbian\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "episode: 628.00, total step: 113144.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.2725, lr: 0.0107\n",
      "episode: 629.00, total step: 113343.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.1222, lr: 0.0107\n",
      "episode: 630.00, total step: 113542.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.2756, lr: 0.0106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MR.Mohebbian\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 631.00, total step: 113741.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.1744, lr: 0.0106\n",
      "episode: 632.00, total step: 113940.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.1424, lr: 0.0106\n",
      "episode: 633.00, total step: 114139.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.1617, lr: 0.0106\n",
      "episode: 634.00, total step: 114338.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.4546, lr: 0.0106\n",
      "episode: 635.00, total step: 114537.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.5923, lr: 0.0106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MR.Mohebbian\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 636.00, total step: 114736.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.7084, lr: 0.0106\n",
      "episode: 637.00, total step: 114881.00, last_episode length: 145.00, last_episode_reward: 144.00, loss: -0.5364, lr: 0.0106\n",
      "episode: 638.00, total step: 115080.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.4694, lr: 0.0106\n",
      "episode: 639.00, total step: 115226.00, last_episode length: 146.00, last_episode_reward: 145.00, loss: -0.1514, lr: 0.0106\n",
      "episode: 640.00, total step: 115425.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.2672, lr: 0.0105\n",
      "episode: 641.00, total step: 115624.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.0175, lr: 0.0105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MR.Mohebbian\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 642.00, total step: 115823.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.1428, lr: 0.0105\n",
      "episode: 643.00, total step: 116022.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.0525, lr: 0.0105\n",
      "episode: 644.00, total step: 116221.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: 0.0912, lr: 0.0105\n",
      "episode: 645.00, total step: 116420.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: 0.0370, lr: 0.0105\n",
      "episode: 646.00, total step: 116619.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.2141, lr: 0.0105\n",
      "episode: 647.00, total step: 116818.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.2621, lr: 0.0105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MR.Mohebbian\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 648.00, total step: 117017.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.0866, lr: 0.0105\n",
      "episode: 649.00, total step: 117216.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.3968, lr: 0.0104\n",
      "episode: 650.00, total step: 117360.00, last_episode length: 144.00, last_episode_reward: 143.00, loss: -0.4587, lr: 0.0104\n",
      "episode: 651.00, total step: 117559.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.4819, lr: 0.0104\n",
      "episode: 652.00, total step: 117758.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.3304, lr: 0.0104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MR.Mohebbian\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 653.00, total step: 117957.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.2162, lr: 0.0104\n",
      "episode: 654.00, total step: 118130.00, last_episode length: 173.00, last_episode_reward: 172.00, loss: -0.1618, lr: 0.0104\n",
      "episode: 655.00, total step: 118329.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.2242, lr: 0.0104\n",
      "episode: 656.00, total step: 118496.00, last_episode length: 167.00, last_episode_reward: 166.00, loss: -0.2898, lr: 0.0104\n",
      "episode: 657.00, total step: 118695.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.4970, lr: 0.0104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MR.Mohebbian\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 658.00, total step: 118894.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.1281, lr: 0.0104\n",
      "episode: 659.00, total step: 119093.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.0159, lr: 0.0103\n",
      "episode: 660.00, total step: 119292.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.1561, lr: 0.0103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MR.Mohebbian\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 661.00, total step: 119491.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.1356, lr: 0.0103\n",
      "episode: 662.00, total step: 119642.00, last_episode length: 151.00, last_episode_reward: 150.00, loss: -0.2764, lr: 0.0103\n",
      "episode: 663.00, total step: 119841.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.3850, lr: 0.0103\n",
      "episode: 664.00, total step: 120040.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.3490, lr: 0.0103\n",
      "episode: 665.00, total step: 120239.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.1967, lr: 0.0103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MR.Mohebbian\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 666.00, total step: 120438.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.4136, lr: 0.0103\n",
      "episode: 667.00, total step: 120605.00, last_episode length: 167.00, last_episode_reward: 166.00, loss: -0.5595, lr: 0.0103\n",
      "episode: 668.00, total step: 120804.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.5326, lr: 0.0103\n",
      "episode: 669.00, total step: 121003.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.1700, lr: 0.0102\n",
      "episode: 670.00, total step: 121165.00, last_episode length: 162.00, last_episode_reward: 161.00, loss: -0.0390, lr: 0.0102\n",
      "episode: 671.00, total step: 121364.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.0658, lr: 0.0102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MR.Mohebbian\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 672.00, total step: 121563.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.1539, lr: 0.0102\n",
      "episode: 673.00, total step: 121762.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.1518, lr: 0.0102\n",
      "episode: 674.00, total step: 121961.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.2742, lr: 0.0102\n",
      "episode: 675.00, total step: 122160.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.3817, lr: 0.0102\n",
      "episode: 676.00, total step: 122359.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.2041, lr: 0.0102\n",
      "episode: 677.00, total step: 122558.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.1299, lr: 0.0102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MR.Mohebbian\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 678.00, total step: 122757.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.2252, lr: 0.0101\n",
      "episode: 679.00, total step: 122956.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.2389, lr: 0.0101\n",
      "episode: 680.00, total step: 123155.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.1383, lr: 0.0101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MR.Mohebbian\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 681.00, total step: 123354.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.3037, lr: 0.0101\n",
      "episode: 682.00, total step: 123553.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.2073, lr: 0.0101\n",
      "episode: 683.00, total step: 123752.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.2891, lr: 0.0101\n",
      "episode: 684.00, total step: 123951.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.4789, lr: 0.0101\n",
      "episode: 685.00, total step: 124150.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.6586, lr: 0.0101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MR.Mohebbian\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 686.00, total step: 124349.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.4452, lr: 0.0101\n",
      "episode: 687.00, total step: 124548.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.4385, lr: 0.0101\n",
      "episode: 688.00, total step: 124747.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.5371, lr: 0.0100\n",
      "episode: 689.00, total step: 124946.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.3193, lr: 0.0100\n",
      "episode: 690.00, total step: 125145.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.2834, lr: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MR.Mohebbian\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 691.00, total step: 125335.00, last_episode length: 190.00, last_episode_reward: 189.00, loss: -0.3703, lr: 0.0100\n",
      "episode: 692.00, total step: 125504.00, last_episode length: 169.00, last_episode_reward: 168.00, loss: -0.4715, lr: 0.0100\n",
      "episode: 693.00, total step: 125703.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.5666, lr: 0.0100\n",
      "episode: 694.00, total step: 125902.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.4903, lr: 0.0100\n",
      "episode: 695.00, total step: 126101.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.2470, lr: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MR.Mohebbian\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 696.00, total step: 126265.00, last_episode length: 164.00, last_episode_reward: 163.00, loss: -0.3904, lr: 0.0100\n",
      "episode: 697.00, total step: 126464.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.5150, lr: 0.0100\n",
      "episode: 698.00, total step: 126652.00, last_episode length: 188.00, last_episode_reward: 187.00, loss: -0.4030, lr: 0.0099\n",
      "episode: 699.00, total step: 126851.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.4295, lr: 0.0099\n",
      "episode: 700.00, total step: 127050.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.3125, lr: 0.0099\n",
      "episode: 701.00, total step: 127234.00, last_episode length: 184.00, last_episode_reward: 183.00, loss: -0.2561, lr: 0.0099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MR.Mohebbian\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 702.00, total step: 127433.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.3324, lr: 0.0099\n",
      "episode: 703.00, total step: 127632.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.4100, lr: 0.0099\n",
      "episode: 704.00, total step: 127831.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.7331, lr: 0.0099\n",
      "episode: 705.00, total step: 128013.00, last_episode length: 182.00, last_episode_reward: 181.00, loss: -0.8590, lr: 0.0099\n",
      "episode: 706.00, total step: 128212.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.7683, lr: 0.0099\n",
      "episode: 707.00, total step: 128411.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.4085, lr: 0.0099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MR.Mohebbian\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 708.00, total step: 128610.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.3643, lr: 0.0098\n",
      "episode: 709.00, total step: 128809.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.7068, lr: 0.0098\n",
      "episode: 710.00, total step: 128985.00, last_episode length: 176.00, last_episode_reward: 175.00, loss: -0.5300, lr: 0.0098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MR.Mohebbian\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 711.00, total step: 129184.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.5315, lr: 0.0098\n",
      "episode: 712.00, total step: 129348.00, last_episode length: 164.00, last_episode_reward: 163.00, loss: -0.4775, lr: 0.0098\n",
      "episode: 713.00, total step: 129547.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.6505, lr: 0.0098\n",
      "episode: 714.00, total step: 129746.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.6007, lr: 0.0098\n",
      "episode: 715.00, total step: 129945.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.3299, lr: 0.0098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MR.Mohebbian\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 716.00, total step: 130144.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.3677, lr: 0.0098\n",
      "episode: 717.00, total step: 130342.00, last_episode length: 198.00, last_episode_reward: 197.00, loss: -0.6300, lr: 0.0098\n",
      "episode: 718.00, total step: 130541.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.6492, lr: 0.0098\n",
      "episode: 719.00, total step: 130740.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.4220, lr: 0.0097\n",
      "episode: 720.00, total step: 130939.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.3391, lr: 0.0097\n",
      "episode: 721.00, total step: 131138.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.4024, lr: 0.0097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MR.Mohebbian\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 722.00, total step: 131337.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.5660, lr: 0.0097\n",
      "episode: 723.00, total step: 131536.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.6673, lr: 0.0097\n",
      "episode: 724.00, total step: 131735.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.5428, lr: 0.0097\n",
      "episode: 725.00, total step: 131934.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.5607, lr: 0.0097\n",
      "episode: 726.00, total step: 132133.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.8382, lr: 0.0097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MR.Mohebbian\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 727.00, total step: 132332.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.8923, lr: 0.0097\n",
      "episode: 728.00, total step: 132531.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.7484, lr: 0.0097\n",
      "episode: 729.00, total step: 132730.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.6771, lr: 0.0096\n",
      "episode: 730.00, total step: 132929.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.4940, lr: 0.0096\n",
      "episode: 731.00, total step: 133128.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.4931, lr: 0.0096\n",
      "episode: 732.00, total step: 133327.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.5571, lr: 0.0096"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MR.Mohebbian\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "episode: 733.00, total step: 133526.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.4687, lr: 0.0096\n",
      "episode: 734.00, total step: 133725.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.3762, lr: 0.0096\n",
      "episode: 735.00, total step: 133924.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.5231, lr: 0.0096\n",
      "episode: 736.00, total step: 134123.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.3922, lr: 0.0096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MR.Mohebbian\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 737.00, total step: 134322.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.4079, lr: 0.0096\n",
      "episode: 738.00, total step: 134513.00, last_episode length: 191.00, last_episode_reward: 190.00, loss: -0.4981, lr: 0.0096\n",
      "episode: 739.00, total step: 134712.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.5944, lr: 0.0095\n",
      "episode: 740.00, total step: 134911.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.4460, lr: 0.0095\n",
      "episode: 741.00, total step: 135110.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.3398, lr: 0.0095\n",
      "episode: 742.00, total step: 135309.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.4730, lr: 0.0095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MR.Mohebbian\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 743.00, total step: 135508.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.3887, lr: 0.0095\n",
      "episode: 744.00, total step: 135707.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.1424, lr: 0.0095\n",
      "episode: 745.00, total step: 135906.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.2538, lr: 0.0095\n",
      "episode: 746.00, total step: 136105.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.3879, lr: 0.0095\n",
      "episode: 747.00, total step: 136304.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.3917, lr: 0.0095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MR.Mohebbian\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 748.00, total step: 136503.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.4655, lr: 0.0095\n",
      "episode: 749.00, total step: 136702.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.4279, lr: 0.0095\n",
      "episode: 750.00, total step: 136901.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.3931, lr: 0.0094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MR.Mohebbian\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 751.00, total step: 137100.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.2924, lr: 0.0094\n",
      "episode: 752.00, total step: 137299.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.4104, lr: 0.0094\n",
      "episode: 753.00, total step: 137498.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.6448, lr: 0.0094\n",
      "episode: 754.00, total step: 137697.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.3053, lr: 0.0094\n",
      "episode: 755.00, total step: 137896.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.0450, lr: 0.0094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MR.Mohebbian\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 756.00, total step: 138095.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.0576, lr: 0.0094\n",
      "episode: 757.00, total step: 138294.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.2978, lr: 0.0094\n",
      "episode: 758.00, total step: 138493.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.4293, lr: 0.0094\n",
      "episode: 759.00, total step: 138692.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.1225, lr: 0.0094\n",
      "episode: 760.00, total step: 138891.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: 0.0683, lr: 0.0093\n",
      "episode: 761.00, total step: 139090.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.1286, lr: 0.0093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MR.Mohebbian\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 762.00, total step: 139289.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.1674, lr: 0.0093\n",
      "episode: 763.00, total step: 139488.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.3419, lr: 0.0093\n",
      "episode: 764.00, total step: 139687.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.4795, lr: 0.0093\n",
      "episode: 765.00, total step: 139886.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.2607, lr: 0.0093\n",
      "episode: 766.00, total step: 140085.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.0557, lr: 0.0093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MR.Mohebbian\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 767.00, total step: 140284.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.1025, lr: 0.0093\n",
      "episode: 768.00, total step: 140483.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.1951, lr: 0.0093\n",
      "episode: 769.00, total step: 140682.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.0789, lr: 0.0093\n",
      "episode: 770.00, total step: 140881.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.0027, lr: 0.0093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MR.Mohebbian\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 771.00, total step: 141080.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: 0.0786, lr: 0.0092\n",
      "episode: 772.00, total step: 141279.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.2545, lr: 0.0092\n",
      "episode: 773.00, total step: 141478.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.3052, lr: 0.0092\n",
      "episode: 774.00, total step: 141677.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.2880, lr: 0.0092\n",
      "episode: 775.00, total step: 141876.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.1432, lr: 0.0092\n",
      "episode: 776.00, total step: 142075.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.2692, lr: 0.0092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MR.Mohebbian\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 777.00, total step: 142274.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.5592, lr: 0.0092\n",
      "episode: 778.00, total step: 142473.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.2777, lr: 0.0092\n",
      "episode: 779.00, total step: 142672.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.0149, lr: 0.0092\n",
      "episode: 780.00, total step: 142871.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.0064, lr: 0.0092\n",
      "episode: 781.00, total step: 143070.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.0241, lr: 0.0092\n",
      "episode: 782.00, total step: 143269.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: 0.0799, lr: 0.0091"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MR.Mohebbian\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "episode: 783.00, total step: 143468.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.0040, lr: 0.0091\n",
      "episode: 784.00, total step: 143667.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.2008, lr: 0.0091\n",
      "episode: 785.00, total step: 143866.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.1570, lr: 0.0091\n",
      "episode: 786.00, total step: 144065.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.3650, lr: 0.0091\n",
      "episode: 787.00, total step: 144264.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.4050, lr: 0.0091"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MR.Mohebbian\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "episode: 788.00, total step: 144463.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.4682, lr: 0.0091\n",
      "episode: 789.00, total step: 144662.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.4686, lr: 0.0091\n",
      "episode: 790.00, total step: 144861.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.5739, lr: 0.0091\n",
      "episode: 791.00, total step: 145060.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.5347, lr: 0.0091\n",
      "episode: 792.00, total step: 145259.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.3423, lr: 0.0091"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MR.Mohebbian\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "episode: 793.00, total step: 145458.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.2226, lr: 0.0090\n",
      "episode: 794.00, total step: 145657.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.0096, lr: 0.0090\n",
      "episode: 795.00, total step: 145856.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.4479, lr: 0.0090\n",
      "episode: 796.00, total step: 146055.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.6541, lr: 0.0090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MR.Mohebbian\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 797.00, total step: 146254.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.6311, lr: 0.0090\n",
      "episode: 798.00, total step: 146453.00, last_episode length: 199.00, last_episode_reward: 198.00, loss: -0.4490, lr: 0.0090\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "agent = Agent()\n",
    "agent.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Render an episode and save as a GIF file\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "# \n",
    "# action = self.env.action_space.sample()\n",
    "# screen, reward, terminal, info = self.env.step(action)\n",
    "\n",
    "def render_episode(env: gym.Env, model, max_steps: int): \n",
    "  screen = env.render(mode='rgb_array')\n",
    "  im = Image.fromarray(screen)\n",
    "\n",
    "  images = [im]\n",
    "  \n",
    "  env.reset()\n",
    "  action = env.action_space.sample()\n",
    "  state, reward, terminal, info = env.step(action)\n",
    "  \n",
    "  for i in range(1, max_steps + 1):\n",
    "    action_probs = model(torch.FloatTensor(state).to(device))\n",
    "    action = np.argmax(np.squeeze(action_probs.cpu().detach().numpy()))\n",
    "\n",
    "    state, _, done, _ = env.step(action)\n",
    "\n",
    "    # Render screen every 10 steps\n",
    "    if i % 2 == 0:\n",
    "      screen = env.render(mode='rgb_array')\n",
    "      images.append(Image.fromarray(screen))\n",
    "\n",
    "    if done:\n",
    "      break\n",
    "\n",
    "  return images\n",
    "\n",
    "\n",
    "# Save GIF image\n",
    "images = render_episode(agent.env, agent.policy_network.pi, 20000)\n",
    "image_file = 'cartpole-v0.gif'\n",
    "# loop=0: loop forever, duration=1: play each frame for 1ms\n",
    "images[0].save(\n",
    "    image_file, save_all=True, append_images=images[1:], loop=0, duration=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<PIL.Image.Image image mode=RGB size=600x400 at 0x1681A3BF8C8>,\n",
       " <PIL.Image.Image image mode=RGB size=600x400 at 0x16810327BC8>,\n",
       " <PIL.Image.Image image mode=RGB size=600x400 at 0x168100D4688>,\n",
       " <PIL.Image.Image image mode=RGB size=600x400 at 0x1681A4FC308>,\n",
       " <PIL.Image.Image image mode=RGB size=600x400 at 0x1681A3BF508>,\n",
       " <PIL.Image.Image image mode=RGB size=600x400 at 0x16810483248>,\n",
       " <PIL.Image.Image image mode=RGB size=600x400 at 0x168100E01C8>,\n",
       " <PIL.Image.Image image mode=RGB size=600x400 at 0x16810364748>,\n",
       " <PIL.Image.Image image mode=RGB size=600x400 at 0x16810364388>,\n",
       " <PIL.Image.Image image mode=RGB size=600x400 at 0x16810364DC8>,\n",
       " <PIL.Image.Image image mode=RGB size=600x400 at 0x1681165FCC8>,\n",
       " <PIL.Image.Image image mode=RGB size=600x400 at 0x168103641C8>,\n",
       " <PIL.Image.Image image mode=RGB size=600x400 at 0x1681044B3C8>,\n",
       " <PIL.Image.Image image mode=RGB size=600x400 at 0x1681044B1C8>,\n",
       " <PIL.Image.Image image mode=RGB size=600x400 at 0x1681044B2C8>,\n",
       " <PIL.Image.Image image mode=RGB size=600x400 at 0x1681044B888>,\n",
       " <PIL.Image.Image image mode=RGB size=600x400 at 0x1681044B348>,\n",
       " <PIL.Image.Image image mode=RGB size=600x400 at 0x1681044BC48>,\n",
       " <PIL.Image.Image image mode=RGB size=600x400 at 0x1681044B608>,\n",
       " <PIL.Image.Image image mode=RGB size=600x400 at 0x1681044B708>,\n",
       " <PIL.Image.Image image mode=RGB size=600x400 at 0x1681044B788>,\n",
       " <PIL.Image.Image image mode=RGB size=600x400 at 0x1681044B048>,\n",
       " <PIL.Image.Image image mode=RGB size=600x400 at 0x16817475888>,\n",
       " <PIL.Image.Image image mode=RGB size=600x400 at 0x1681044B5C8>,\n",
       " <PIL.Image.Image image mode=RGB size=600x400 at 0x1681046D248>,\n",
       " <PIL.Image.Image image mode=RGB size=600x400 at 0x1681046D288>,\n",
       " <PIL.Image.Image image mode=RGB size=600x400 at 0x168115A3108>,\n",
       " <PIL.Image.Image image mode=RGB size=600x400 at 0x168100DC808>,\n",
       " <PIL.Image.Image image mode=RGB size=600x400 at 0x168174704C8>,\n",
       " <PIL.Image.Image image mode=RGB size=600x400 at 0x168100DCA48>,\n",
       " <PIL.Image.Image image mode=RGB size=600x400 at 0x1681046DF48>,\n",
       " <PIL.Image.Image image mode=RGB size=600x400 at 0x168103EB908>,\n",
       " <PIL.Image.Image image mode=RGB size=600x400 at 0x168103EB388>,\n",
       " <PIL.Image.Image image mode=RGB size=600x400 at 0x168103EBEC8>,\n",
       " <PIL.Image.Image image mode=RGB size=600x400 at 0x16810430448>,\n",
       " <PIL.Image.Image image mode=RGB size=600x400 at 0x168103EB788>,\n",
       " <PIL.Image.Image image mode=RGB size=600x400 at 0x16810327248>,\n",
       " <PIL.Image.Image image mode=RGB size=600x400 at 0x168103AF508>,\n",
       " <PIL.Image.Image image mode=RGB size=600x400 at 0x16810430608>,\n",
       " <PIL.Image.Image image mode=RGB size=600x400 at 0x168103825C8>,\n",
       " <PIL.Image.Image image mode=RGB size=600x400 at 0x168103D1288>,\n",
       " <PIL.Image.Image image mode=RGB size=600x400 at 0x168103AF0C8>,\n",
       " <PIL.Image.Image image mode=RGB size=600x400 at 0x168103D14C8>,\n",
       " <PIL.Image.Image image mode=RGB size=600x400 at 0x168100BC448>,\n",
       " <PIL.Image.Image image mode=RGB size=600x400 at 0x168100BC9C8>,\n",
       " <PIL.Image.Image image mode=RGB size=600x400 at 0x168100BC2C8>,\n",
       " <PIL.Image.Image image mode=RGB size=600x400 at 0x1681046DE48>,\n",
       " <PIL.Image.Image image mode=RGB size=600x400 at 0x168103D1E88>,\n",
       " <PIL.Image.Image image mode=RGB size=600x400 at 0x168100BC808>,\n",
       " <PIL.Image.Image image mode=RGB size=600x400 at 0x168116CAA08>,\n",
       " <PIL.Image.Image image mode=RGB size=600x400 at 0x16816C48448>,\n",
       " <PIL.Image.Image image mode=RGB size=600x400 at 0x1681009BAC8>,\n",
       " <PIL.Image.Image image mode=RGB size=600x400 at 0x16810341748>,\n",
       " <PIL.Image.Image image mode=RGB size=600x400 at 0x16816C4BB48>,\n",
       " <PIL.Image.Image image mode=RGB size=600x400 at 0x168116ACD48>,\n",
       " <PIL.Image.Image image mode=RGB size=600x400 at 0x168115E4A88>,\n",
       " <PIL.Image.Image image mode=RGB size=600x400 at 0x168103414C8>,\n",
       " <PIL.Image.Image image mode=RGB size=600x400 at 0x168102F6AC8>,\n",
       " <PIL.Image.Image image mode=RGB size=600x400 at 0x16816BE49C8>,\n",
       " <PIL.Image.Image image mode=RGB size=600x400 at 0x168174713C8>,\n",
       " <PIL.Image.Image image mode=RGB size=600x400 at 0x16816C48E88>,\n",
       " <PIL.Image.Image image mode=RGB size=600x400 at 0x1681A508048>,\n",
       " <PIL.Image.Image image mode=RGB size=600x400 at 0x1681A5080C8>,\n",
       " <PIL.Image.Image image mode=RGB size=600x400 at 0x1681A508148>,\n",
       " <PIL.Image.Image image mode=RGB size=600x400 at 0x1681A5081C8>,\n",
       " <PIL.Image.Image image mode=RGB size=600x400 at 0x1681A508248>,\n",
       " <PIL.Image.Image image mode=RGB size=600x400 at 0x1681A5082C8>,\n",
       " <PIL.Image.Image image mode=RGB size=600x400 at 0x1681A508348>,\n",
       " <PIL.Image.Image image mode=RGB size=600x400 at 0x1681A5083C8>,\n",
       " <PIL.Image.Image image mode=RGB size=600x400 at 0x1681A508448>,\n",
       " <PIL.Image.Image image mode=RGB size=600x400 at 0x1681A5084C8>,\n",
       " <PIL.Image.Image image mode=RGB size=600x400 at 0x1681A508548>,\n",
       " <PIL.Image.Image image mode=RGB size=600x400 at 0x1681A5085C8>,\n",
       " <PIL.Image.Image image mode=RGB size=600x400 at 0x1681A508648>,\n",
       " <PIL.Image.Image image mode=RGB size=600x400 at 0x1681A5086C8>,\n",
       " <PIL.Image.Image image mode=RGB size=600x400 at 0x1681A508748>,\n",
       " <PIL.Image.Image image mode=RGB size=600x400 at 0x1681A5087C8>,\n",
       " <PIL.Image.Image image mode=RGB size=600x400 at 0x1681A508848>,\n",
       " <PIL.Image.Image image mode=RGB size=600x400 at 0x1681A5088C8>,\n",
       " <PIL.Image.Image image mode=RGB size=600x400 at 0x1681A508948>,\n",
       " <PIL.Image.Image image mode=RGB size=600x400 at 0x1681A5089C8>,\n",
       " <PIL.Image.Image image mode=RGB size=600x400 at 0x1681A508A48>,\n",
       " <PIL.Image.Image image mode=RGB size=600x400 at 0x1681A508088>,\n",
       " <PIL.Image.Image image mode=RGB size=600x400 at 0x1681A508B48>,\n",
       " <PIL.Image.Image image mode=RGB size=600x400 at 0x1681A508BC8>,\n",
       " <PIL.Image.Image image mode=RGB size=600x400 at 0x1681A508C48>,\n",
       " <PIL.Image.Image image mode=RGB size=600x400 at 0x1681A508CC8>,\n",
       " <PIL.Image.Image image mode=RGB size=600x400 at 0x1681A508D48>,\n",
       " <PIL.Image.Image image mode=RGB size=600x400 at 0x1681A508DC8>,\n",
       " <PIL.Image.Image image mode=RGB size=600x400 at 0x1681A508E48>,\n",
       " <PIL.Image.Image image mode=RGB size=600x400 at 0x1681A508EC8>,\n",
       " <PIL.Image.Image image mode=RGB size=600x400 at 0x168100BCC88>,\n",
       " <PIL.Image.Image image mode=RGB size=600x400 at 0x1681A508FC8>,\n",
       " <PIL.Image.Image image mode=RGB size=600x400 at 0x1681A503088>,\n",
       " <PIL.Image.Image image mode=RGB size=600x400 at 0x1681A503108>,\n",
       " <PIL.Image.Image image mode=RGB size=600x400 at 0x1681A503188>,\n",
       " <PIL.Image.Image image mode=RGB size=600x400 at 0x1681A503208>,\n",
       " <PIL.Image.Image image mode=RGB size=600x400 at 0x1681A503288>,\n",
       " <PIL.Image.Image image mode=RGB size=600x400 at 0x1681A503308>,\n",
       " <PIL.Image.Image image mode=RGB size=600x400 at 0x1681A503388>]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "366252978e52bb2df929d3934aeb3ff29dfa67e45e575a59a0b0194f7beef5a9"
  },
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
